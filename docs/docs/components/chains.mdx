import ThemedImage from "@theme/ThemedImage";
import useBaseUrl from "@docusaurus/useBaseUrl";
import ZoomableImage from "/src/theme/ZoomableImage.js";
import Admonition from "@theme/Admonition";

# Chains

Chains, in the context of language models, refer to a series of calls made to a language model. This approach allows for using the output of one call as the input for another. Different chain types facilitate varying complexity levels, making them useful for creating pipelines and executing specific scenarios.

---

## CombineDocsChain

`CombineDocsChain` includes methods to combine or aggregate loaded documents for question-answering functionality.

Acts as a proxy for LangChain’s [documents](https://python.langchain.com/docs/modules/chains/document/) chains produced by the `load_qa_chain` function.

**Parameters**:

- **LLM:** Language Model to use in the chain.
- **chain_type:** Type of chain to be used, each applying a different combination strategy:
  - **stuff**: Most straightforward document chain. It takes a list of documents, inserts them all into a prompt, and passes that prompt to an LLM. Suitable for cases where documents are small and few.
  - **map_reduce**: Applies an LLM to each document individually (the `Map` step), treating the output as a new document. It then combines these documents to get a single output (the `Reduce` step). Compression may occur to ensure documents fit in the final chain.
  - **map_rerank**: Runs an initial prompt on each document to complete a task and score its certainty. Returns the highest-scoring response.
  - **refine**: Iteratively updates its answer by looping over the input documents. Each document, along with the latest intermediate answer, is passed to an LLM to generate a new response. This method suits tasks requiring analysis of more documents than the model's context can handle, though it can be less effective for tasks requiring detailed cross-referencing or comprehensive information.

---

## ConversationChain

`ConversationChain` facilitates dynamic, interactive conversations with a language model, ideal for chatbots or virtual assistants.

**Parameters**:

- **LLM:** Language Model to use in the chain.
- **Memory:** Default memory store.
- **input_key:** Specifies the key under which user input is stored in the conversation memory, enabling the chain to process and generate responses.
- **output_key:** Specifies the key under which the generated response is stored, allowing retrieval of the response using this key.
- **verbose:** Controls the verbosity of the chain's output. Set to `True` to enable detailed internal state outputs, useful for debugging and understanding the chain's behavior. Defaults to `False`.

---

## ConversationalRetrievalChain

`ConversationalRetrievalChain` combines document search with question-answering capabilities, extracting information and providing answers.

A retriever finds documents based on a query but doesn’t store them; it returns the documents matching the query.

**Parameters**:

- **LLM:** Language Model to use in the chain.
- **Memory:** Default memory store.
- **Retriever:** The retriever used to fetch relevant documents.
- **chain_type:** Type of chain to be used, each applying a different combination strategy:
  - **stuff**: Inserts a list of documents into a prompt and passes it to an LLM. Suitable for cases where documents are small and few.
  - **map_reduce**: Processes each document with an LLM separately, combines them for a single output. Compressions may occur to fit documents into the final chain.
  - **map_rerank**: Scores responses based on certainty from each document, returns the highest.
  - **refine**: Updates answers iteratively by looping through documents, passing each with intermediate answers to an LLM for a new response. This method is beneficial for tasks that involve extensive document analysis.
- **return_source_documents:** Specifies whether to include source documents used in the output. Useful for providing context or references to the user. Defaults to `True`.
- **verbose:** Controls verbosity of output. Set to `True` for detailed logs, useful for debugging. Defaults to `False`.

---
